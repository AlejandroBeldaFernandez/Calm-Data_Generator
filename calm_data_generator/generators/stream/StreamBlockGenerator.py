import os
import pandas as pd
import warnings
from .StreamReporter import StreamReporter
from .GeneratorFactory import GeneratorFactory, GeneratorType, GeneratorConfig
from .StreamGenerator import StreamGenerator
from calm_data_generator.generators.drift.DriftInjector import DriftInjector
from calm_data_generator.generators.dynamics.ScenarioInjector import ScenarioInjector
from calm_data_generator.generators.configs import DriftConfig, ReportConfig
from typing import List, Dict, Optional, Any, Union


# Suppress common warnings for cleaner output
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)


class SyntheticBlockGenerator:
    """
    Generates synthetic datasets composed of multiple, distinct blocks.

    This class simplifies the creation of block-structured datasets, where each block can have
    different properties or be generated by a different concept. It is particularly useful for
    simulating non-stationary environments and concept drift.

    Key Features:
    - **Block-based Generation**: Creates a single dataset from multiple sequential blocks.
    - **Simplified Interface**: Provides a `generate_blocks_simple` method that accepts string-based
      method names (e.g., 'sea', 'agrawal') and dictionaries for parameters.
    - **Concept Drift Simulation**: Easily simulate drift by providing different generator parameters
      for different blocks.
    - **Timestamp Alignment**: Can automatically add a timestamp column that aligns with the block structure.
    - **Integrated Reporting**: Generates a comprehensive report for the final block-structured dataset.
    """

    def generate_blocks_simple(
        self,
        output_dir: str,
        filename: str,
        n_blocks: int,
        total_samples: int,
        methods,
        method_params=None,
        n_samples_block=None,
        target_col="target",
        balance: bool = False,
        random_state: int = None,
        date_start: str = None,
        date_step: dict = None,
        date_col: str = "timestamp",
        generate_report: bool = True,
        drift_config: Optional[List[Union[Dict, DriftConfig]]] = None,
        dynamics_config: Optional[Dict] = None,
        report_config: Optional[Union[ReportConfig, Dict]] = None,
    ):
        """
        A simplified interface for generating block-structured datasets using string-based method names.

        Args:
            output_dir (str): Directory to save the output files.
            filename (str): Name of the final output CSV file.
            n_blocks (int): The number of blocks to generate.
            total_samples (int): The total number of samples across all blocks.
            methods (Union[str, List[str]]): The name of the generator method(s) to use (e.g., 'sea').
                                             If a single string, it's used for all blocks.
            method_params (Union[Dict, List[Dict]]): Parameters for the generator(s).
            n_samples_block (Union[int, List[int]]): Number of samples per block.
            target_col (str): Name of the target column.
            balance (bool): If True, balances the class distribution within each block.
            random_state (int): Seed for reproducibility.
            date_start (str): Start date for block-aligned timestamp injection.
            date_step (dict): Time step between blocks (e.g., {'days': 7}).
            date_col (str): Name of the timestamp column.
        """
        os.makedirs(output_dir, exist_ok=True)

        method_mapping = {
            "sea": GeneratorType.SEA,
            "agrawal": GeneratorType.AGRAWAL,
            "hyperplane": GeneratorType.HYPERPLANE,
            "sine": GeneratorType.SINE,
            "stagger": GeneratorType.STAGGER,
            "random_tree": GeneratorType.RANDOM_TREE,
            "mixed": GeneratorType.MIXED,
            "friedman": GeneratorType.FRIEDMAN,
            "random_rbf": GeneratorType.RANDOM_RBF,
        }

        methods = self._ensure_list(methods, n_blocks)
        if len(set(methods)) > 1:
            raise ValueError(
                "All blocks must use the same generator type. Multiple methods found."
            )

        if methods[0] not in method_mapping:
            raise ValueError(
                f"Invalid method '{methods[0]}'. Choose one of {list(method_mapping.keys())}"
            )

        method_params = self._ensure_list(method_params or {}, n_blocks)

        if n_samples_block is None:
            base_samples = total_samples // n_blocks
            n_samples_block = [base_samples] * n_blocks
            n_samples_block[-1] += total_samples % n_blocks
        else:
            n_samples_block = self._ensure_list(n_samples_block, n_blocks)

        factory = GeneratorFactory()
        generators = []

        for i, params in enumerate(method_params):
            config_params = params.copy()
            if random_state is not None:
                config_params["random_state"] = (random_state + i) % (2**32 - 1)

            config = GeneratorConfig(**config_params)
            generator_instance = factory.create_generator(
                method_mapping[methods[0]], config
            )
            generators.append(generator_instance)

        return self.generate(
            output_dir=output_dir,
            filename=filename,
            n_blocks=n_blocks,
            total_samples=total_samples,
            n_samples_block=n_samples_block,
            generators=generators,
            target_col=target_col,
            balance=balance,
            date_start=date_start,
            date_step=date_step,
            date_col=date_col,
            generate_report=generate_report,
            drift_config=drift_config,
            dynamics_config=dynamics_config,
            report_config=report_config,
        )

    def _ensure_list(self, value, n_blocks):
        """Ensures that a value is a list of length n_blocks."""
        if isinstance(value, list):
            if len(value) == 1:
                return value * n_blocks
            elif len(value) == n_blocks:
                return value
            else:
                raise ValueError(
                    f"List length {len(value)} does not match n_blocks={n_blocks}."
                )
        else:
            return [value] * n_blocks

    def generate(
        self,
        output_dir: str,
        filename: str,
        n_blocks: int,
        total_samples: int,
        n_samples_block,
        generators,
        target_col="target",
        balance: bool = False,
        date_start: str = None,
        date_step: dict = None,
        date_col: str = "timestamp",
        generate_report: bool = True,
        drift_config: Optional[List[Union[Dict, DriftConfig]]] = None,
        dynamics_config: Optional[Dict] = None,
        report_config: Optional[Union[ReportConfig, Dict]] = None,
        block_labels: Optional[List[Any]] = None,
    ) -> str:
        """
        Generates a block-structured dataset from a list of instantiated River generators.

        Args:
            output_dir (str): Directory to save the output files.
            filename (str): Name of the final output CSV file.
            n_blocks (int): The number of blocks to generate.
            total_samples (int): The total number of samples across all blocks.
            n_samples_block (List[int]): A list specifying the number of samples for each block.
            generators (List): A list of instantiated River generator objects.
            target_col (str): Name of the target column.
            balance (bool): If True, balances the class distribution within each block.
            date_start (str): Start date for block-aligned timestamp injection.
            date_step (dict): Time step between blocks (e.g., {'days': 7}).
            date_col (str): Name of the timestamp column.
            generate_report (bool): If True, generates a comprehensive report for the dataset.

        Returns:
            str: The full path to the generated CSV file.
        """

        n_samples_block = self._ensure_list(n_samples_block, n_blocks)
        generators = self._ensure_list(generators, n_blocks)
        if len(set(type(g) for g in generators)) > 1:
            raise ValueError("All generator instances must be of the same type.")

        if sum(n_samples_block) != total_samples:
            raise ValueError(
                f"Total samples ({total_samples}) must equal the sum of instances per block ({sum(n_samples_block)})"
            )

        if block_labels:
            if len(block_labels) != n_blocks:
                raise ValueError(
                    f"Length of block_labels ({len(block_labels)}) must match n_blocks ({n_blocks})."
                )
        else:
            block_labels = list(range(1, n_blocks + 1))

        os.makedirs(output_dir, exist_ok=True)
        full_path = os.path.join(output_dir, filename)

        block_dates = None
        if date_start:
            start_ts = pd.to_datetime(date_start)
            step = pd.DateOffset(**(date_step or {"days": 1}))
            block_dates = [start_ts + step * i for i in range(n_blocks)]

        all_data = []
        synthetic_generator = StreamGenerator()

        for i in range(n_blocks):
            gen = generators[i]
            n_samples_this_block = n_samples_block[i]
            current_block_label = block_labels[i]

            block_df = synthetic_generator.generate(
                generator_instance=gen,
                metadata_generator_instance=gen,
                output_dir=output_dir,
                filename=f"block_{str(current_block_label)}.csv",
                n_samples=n_samples_this_block,
                target_col=target_col,
                balance=balance,
                date_start=block_dates[i].isoformat() if block_dates else None,
                date_every=n_samples_this_block,  # Assign the same date to the whole block
                date_col=date_col,
                save_dataset=False,
                generate_report=False,
            )
            block_df["block"] = current_block_label
            all_data.append(block_df)

        df = pd.concat(all_data, ignore_index=True)

        # --- Dynamics Injection ---
        if dynamics_config:
            # Create a simple logger for fallback if needed, or use print?
            # The class doesn't have a logger instantiated. It uses tf.get_logger and setLevel.
            # I'll use warnings or just proceed. StreamGenerator has a logger.
            # I will instantiate DynamicsInjector
            injector = ScenarioInjector()
            if "evolve_features" in dynamics_config:
                evolve_args = dynamics_config["evolve_features"]
                df = injector.evolve_features(
                    df, time_col=date_col, evolution_config=evolve_args
                )
            if "construct_target" in dynamics_config:
                target_args = dynamics_config["construct_target"]
                df = injector.construct_target(df, **target_args)

        # --- Drift Injection ---
        # --- Drift Injection ---
        if drift_config:
            injector = DriftInjector(
                original_df=df,
                output_dir=output_dir,
                generator_name="SyntheticBlockGenerator_Drifted",
                target_column=target_col,
                block_column="block",
                time_col=date_col,
            )

            # Use the updated inject_multiple_types_of_drift which handles DriftConfig objects
            df = injector.inject_multiple_types_of_drift(
                df=df,
                schedule=drift_config,
                time_col=date_col,
                block_column="block",
                target_column=target_col,
            )

        df.to_csv(full_path, index=False)

        print(f"Generated {total_samples} samples in {n_blocks} blocks at: {full_path}")

        if generate_report:
            # Resolve ReportConfig
            effective_report_config = report_config
            if report_config:
                if isinstance(report_config, dict):
                    effective_report_config = ReportConfig(**report_config)
                # Update output_dir if needed
                if output_dir and output_dir != effective_report_config.output_dir:
                    effective_report_config.output_dir = output_dir

            reporter = StreamReporter(verbose=True)
            reporter.generate_report(
                synthetic_df=df,
                generator_name="SyntheticBlockGenerator",
                output_dir=output_dir,
                target_column=target_col,
                block_column="block",
                time_col=date_col,
                report_config=effective_report_config,
            )

        return full_path
