# RealGenerator - Referencia Completa

**Ubicaci√≥n:** `calm_data_generator.generators.tabular.RealGenerator`

El generador principal para la s√≠ntesis de datos tabulares a partir de datasets reales.

---

## Inicializaci√≥n

```python
from calm_data_generator import RealGenerator

gen = RealGenerator(
    auto_report=True,       # Generar informe autom√°ticamente tras s√≠ntesis
    minimal_report=False,   # Si es True, informe m√°s r√°pido sin correlaciones/PCA
    random_state=42,        # Semilla para reproducibilidad
    logger=None,            # Logger de Python personalizado opcional
)
```

### Par√°metros del Constructor

| Par√°metro | Tipo | Defecto | Descripci√≥n |
|-----------|------|---------|-------------|
| `auto_report` | bool | `True` | Generar informe de calidad autom√°ticamente |
| `minimal_report` | bool | `False` | Informe simplificado (m√°s r√°pido) |
| `random_state` | int | `None` | Semilla para reproducibilidad |
| `logger` | Logger | `None` | Instancia de Logger de Python personalizada |

---

## M√©todo Principal: `generate()`

```python
# Nuevos Imports de Configuraci√≥n
from calm_data_generator.generators.configs import DriftConfig, ReportConfig, DateConfig

synthetic_df = gen.generate(
    data=df,                          # DataFrame original (requerido)
    n_samples=1000,                   # N√∫mero de muestras a generar (requerido)
    method="ctgan",                   # M√©todo de s√≠ntesis
    
    # Objetos de Configuraci√≥n
    report_config=ReportConfig(       # Configuraci√≥n de informes
        output_dir="./output",
        target_column="target"
    ),
    
    # Inyecci√≥n de Drift
    drift_injection_config=[
        DriftConfig(
            method="inject_feature_drift",
            feature_cols=["age"],
            drift_type="shift", 
            magnitude=0.5
        )
    ],
    
    # Los argumentos legacy a√∫n son soportados pero se recomiendan los objetos Config
    # target_col="target", 
    # output_dir="./output" 
)
```

### Par√°metros de `generate()`

| Par√°metro | Tipo | Defecto | Descripci√≥n |
|-----------|------|---------|-------------|
| `data` | DataFrame | - | Dataset original (requerido) |
| `n_samples` | int | - | N√∫mero de muestras a generar (requerido) |
| `method` | str | `"cart"` | M√©todo de s√≠ntesis |
| `target_col` | str | `None` | Columna objetivo para balanceo |
| `output_dir` | str | `None` | Directorio para archivos de salida |
| `generator_name` | str | `"RealGenerator"` | Nombre base para archivos de salida |
| `save_dataset` | bool | `False` | Guardar dataset generado como CSV |
| `custom_distributions` | Dict | `None` | Distribuci√≥n forzada por columna |
| `date_col` | str | `None` | Nombre de columna de fecha a inyectar |
| `date_start` | str | `None` | Fecha de inicio ("YYYY-MM-DD") |
| `date_step` | Dict | `None` | Incremento temporal (ej., `{"days": 1}`) |
| `date_every` | int | `1` | Incrementar fecha cada N filas |
| `drift_injection_config` | List[Union[Dict, DriftConfig]] | `None` | Configuraci√≥n de drift post-generaci√≥n |
| `dynamics_config` | Dict | `None` | Configuraci√≥n de evoluci√≥n din√°mica |
| `**kwargs` | Dict | `None` | Hiperpar√°metros espec√≠ficos  |
| `constraints` | List[Dict] | `None` | Restricciones de integridad |
| `adversarial_validation` | bool | `False` | Activar reporte de discriminador (Real vs Sint√©tico) |

---

## Referencia Completa de `**kwargs`

El diccionario `**kwargs` permite el ajuste fino de par√°metros internos para cada m√©todo de s√≠ntesis.

### Deep Learning (Synthcity)

| Par√°metro | M√©todos | Descripci√≥n |
|-----------|---------|-------------|
| `epochs` | `ctgan`, `tvae` | N√∫mero de √©pocas de entrenamiento (defecto: 300) |
| `batch_size` | `ctgan`, `tvae` | Tama√±o del batch de entrenamiento (defecto: 500) |
| `n_units_conditional` | `ctgan`, `tvae` | Unidades en capas condicionales |
| `lr` | `ctgan`, `tvae` | Tasa de aprendizaje (Learning rate) |

**Ejemplo:**
```python
gen.generate(
    df, 1000,
    method="ctgan",
    epochs=500,
    batch_size=256
)
```


### Machine Learning Cl√°sico (CART, RF, LGBM)

| Par√°metro | M√©todos | Descripci√≥n |
|-----------|---------|-------------|
| `balance_target` | Todos ML | Si es True y `target_col` existe, balancea clases antes de entrenar |
| `n_estimators` | RF, LGBM | N√∫mero de √°rboles |
| `max_depth` | CART, RF | Profundidad m√°xima |

**Ejemplo:**
```python
method="rf",
target_col="churn",
balance_target=True,
n_estimators=100,

```

### Single-Cell (scVI)

Estos m√©todos est√°n dise√±ados espec√≠ficamente para **datos transcript√≥micos (RNA-seq)**. Utilizan modelos generativos profundos para manejar la dispersi√≥n (sparsity) y el ruido t√©cnico caracter√≠stico de los datos biol√≥gicos. Son ideales para corregir "efectos de lote" (batch effects) y generar perfiles de expresi√≥n gen√©tica sint√©ticos coherentes.

**Formato de Entrada:** Acepta tanto `pd.DataFrame` como objetos `AnnData` directamente.

#### scVI (Single-cell Variational Inference)

**Entrada DataFrame:**
```python
synthetic = gen.generate(
    data=expression_df,      # Filas=c√©lulas, Columnas=genes
    n_samples=1000,
    method="scvi",
    target_col="cell_type",  # Columna de metadatos opcional
    epochs=100,
    n_latent=10,
    n_layers=1,
    
)

# GEARS - Predicci√≥n de Perturbaciones basada en Grafos
synthetic = gen.generate(
    expression_df, 500,
    method='gears',
    perturbations=['GENE1', 'GENE2'],  # Requerido: genes a perturbar
    epochs=20,
    batch_size=32,
    device='cpu'
)
> **IMPORTANTE:** GEARS requiere instalaci√≥n desde el c√≥digo fuente (`pip install "git+https://github.com/snap-stanford/GEARS.git@f374e43"`) y PyTorch >= 2.4.0.

**Formato de Entrada:** Acepta objetos `pd.DataFrame`, `AnnData` o rutas de archivo (`.h5`, `.h5ad` o `.csv`) directamente.

**Formato de Entrada:** Acepta objetos `pd.DataFrame`, `AnnData` o rutas de archivo (`.h5`, `.h5ad` o `.csv`) directamente.

**Uso de Rutas de Archivo (H5/H5AD/CSV):**
```python
# ¬°El generador carga el archivo autom√°ticamente por ti!
synthetic = gen.generate(
    data="datos_single_cell.csv",  # O .h5ad, .h5
    n_samples=1000,
    method="scvi",
    target_col="cell_type"
)
```


**Entrada AnnData (Recomendado para datos single-cell):**
```python
import anndata

# Crear o cargar objeto AnnData
adata = anndata.read_h5ad("single_cell_data.h5ad")

synthetic = gen.generate(
    data=adata,              # Pasar AnnData directamente
    n_samples=1000,
    method="scvi",
    target_col="cell_type",  # Debe estar en adata.obs
    epochs=100,
    n_latent=10,
    n_layers=1,
    
)
# Retorna pd.DataFrame con columnas de genes + metadatos
```

| Par√°metro | Descripci√≥n |
|-----------|-------------|
| `epochs` | √âpocas de entrenamiento (default: 100) |
| `n_latent` | Dimensionalidad del espacio latente (default: 10) |
| `n_layers` | N√∫mero de capas ocultas (default: 1) |



> **Soporte AnnData:** Al pasar un objeto `AnnData`, este se utiliza directamente sin conversi√≥n, preservando la estructura original. El resultado es siempre un `pd.DataFrame` que contiene tanto la expresi√≥n g√©nica como los metadatos de las observaciones (`obs`).


```

| Par√°metro | Descripci√≥n |
|-----------|-------------|
| `epochs` | √âpocas de entrenamiento (default: 100) |
| `n_latent` | Dimensionalidad del espacio latente (default: 10) |
| `condition_col` | Columna con etiquetas de condici√≥n/lote (requerido) |



---


---

## Caracter√≠sticas Avanzadas

### Inyecci√≥n de Fechas (DateConfig)

Puedes inyectar una columna de fecha/hora en los datos generados usando `DateConfig`.

```python
from calm_data_generator.generators.configs import DateConfig

synthetic = gen.generate(
    data=df,
    n_samples=1000,
    method="cart",
    date_config=DateConfig(
        date_col="timestamp",
        start_date="2024-06-01",
        step={"hours": 1},  # Incremento temporal
        frequency=1         # Incrementar cada N filas
    )
)
```

## Manejo de Datos Desbalanceados

`RealGenerator` ofrece varias estrategias para trabajar con datasets fuertemente desbalanceados (ej. detecci√≥n de fraude, diagn√≥sticos raros):

### 1. Re-balanceo Autom√°tico (`balance_target=True`)
Utiliza t√©cnicas de re-muestreo antes o durante el entrenamiento para generar un dataset sint√©tico equilibrado.
*   **Ideal para:** Entrenar modelos de clasificaci√≥n robustos que requieren clases balanceadas.
*   **Comportamiento:** Si el original es 99% clase A y 1% clase B, el resultado ser√° aprox. 50% A y 50% B.
*   **M√©todos compatibles:** `cart`, `rf`, `lgbm`.

### 2. Control Manual de Distribuci√≥n
Puede forzar la distribuci√≥n de la clase objetivo usando `DriftInjector`.
*   **Ideal para:** Escenarios "What-If" (ej. "¬øQu√© pasa si el fraude aumenta al 10%?").
*   **M√©todo:** `DriftInjector.inject_label_shift` post-generaci√≥n.

### 3. T√©cnicas de Oversampling
M√©todos cl√°sicos para aumentar la clase minoritaria mediante interpolaci√≥n.
*   **M√©todos:** `smote` (Synthetic Minority Over-sampling Technique), `adasyn` (Adaptive Synthetic Sampling).
*   **Ideal para:** Datasets num√©ricos peque√±os donde se necesita aumentar la representaci√≥n de casos raros.

### 4. Fidelidad Estad√≠stica (Por defecto)
Si no se especifica ninguna opci√≥n, los modelos generativos avanzados (`ctgan`, `tvae`) aprender√°n y replicar√°n la distribuci√≥n original, preservando el desbalance real.
*   **Ideal para:** An√°lisis exploratorio fiel a la realidad o validaci√≥n de sistemas en condiciones reales.

---

## M√©todos Soportados

| M√©todo | Tipo | Descripci√≥n |
|--------|------|-------------|
| `cart` | ML | √Årboles de Clasificaci√≥n y Regresi√≥n (R√°pido, bueno para estructura) |
| `rf` | ML | Random Forest (Robusto, m√°s lento que CART) |
| `ctgan` | DL | Conditional GAN para tablas (V√≠a Synthcity) |
| `tvae` | DL | Variational Autoencoder para tablas (V√≠a Synthcity) |
| `copula` | Estad√≠stico | S√≠ntesis basada en Copulas Gaussianas |
| `diffusion` | DL | Difusi√≥n Tabular (DDPM) | **Experimental**. Requiere `calm-data-generator[deeplearning]` |
| `smote` | Aug. | Sobremuestreo SMOTE | Instalaci√≥n base |
| `adasyn` | Aug. | Muestreo adaptativo ADASYN | Instalaci√≥n base |

| `gmm` | Estad√≠stico | Modelos de Mezcla Gaussiana | Instalaci√≥n base |
| `scvi` | Single-Cell | scVI (Variational Inference) para RNA-seq | Requiere `scvi-tools` |
| `gears` | Single-Cell | GEARS (Predicci√≥n de Perturbaciones) | Requiere `gears` |

---

## Escenarios de Uso Comunes (Gu√≠a R√°pida)

### 1. Series Temporales (Time Series)
Para datos de series temporales, usa m√©todos tabulares est√°ndar (CTGAN, TVAE, etc.) en datos temporales estructurados adecuadamente.
*   **Proyecci√≥n de Futuro (Forecasting):** No es el caso de uso principal. Usa `StreamGenerator` para flujos infinitos o inyecci√≥n de fechas manual.


### 2. Clasificaci√≥n y Regresi√≥n (Supervisado)
Si tienes una columna `target` (ej. precio, churn) y la relaci√≥n $X \rightarrow Y$ es cr√≠tica:
*   Usa `method="lgbm"` (LightGBM) o `method="rf"` (Random Forest).
*   Especifica siempre `target_col="nombre_columna"`.
    ```python
    # El generador detecta autom√°ticamente si es Regresi√≥n o Clasificaci√≥n
    gen.generate(data, target_col="precio", method="lgbm") 
    ```

### 3. Clustering (No Supervisado)
Si no hay un target claro y quieres preservar grupos naturales de datos:
*   Usa `method="gmm"` (Gaussian Mixture Models, v√≠a librer√≠a externa si disponible) o `method="tvae"` (Variational Autoencoder).
    ```python
    gen.generate(data, method="tvae")
    ```

### 4. Multi-Label (Etiquetas M√∫ltiples)
Si una celda contiene m√∫ltiples valores (ej: `["A", "B", "C"]`) o formato string `"A,B,C"`:
*   **Limitaci√≥n:** Los modelos est√°ndar no manejan bien listas dentro de celdas.
*   **Soluci√≥n:** Transforma la columna a **One-Hot Encoding** (m√∫ltiples columnas binarias `is_A`, `is_B`) antes de pasarla al generador. Los modelos basados en √°rboles (`lgbm`, `cart`) aprender√°n las correlaciones entre etiquetas (ej: si `is_A=1` suele implicar `is_B=1`).

### 5. Datos por Bloques (Blocks)
Si tus datos est√°n fragmentados l√≥gicamente (ej: por Tiendas, Pa√≠ses, Pacientes) y quieres modelos independientes para cada uno:
*   Usa **`RealBlockGenerator`** en lugar de `RealGenerator`.
    ```python
    block_gen = RealBlockGenerator()
    block_gen.generate(data, block_column="TiendaID", method="cart") 
    ```
    *Esto entrena un modelo diferente para cada TiendaID.*

### 6. Manejo de Datos Desbalanceados (Imbalance)
Si tu columna objetivo (`target`) tiene clases muy minoritarias que quieres potenciar:
*   **Balanceo Autom√°tico:** Usa `balance_target=True`. El generador aplicar√° t√©cnicas de sobremuestreo (SMOTE/RandomOverSampler) internamente para que el modelo aprenda por igual de todas las clases.
    ```python
    gen.generate(data, target_col="fraude", balance_target=True, method="cart")
    ```
*   **Distribuci√≥n Personalizada:** Si quieres una proporci√≥n exacta (ej: 70% Clase A, 30% Clase B):
    ```python
    gen.generate(data, target_col="nivel", custom_distributions={"nivel": {"Bajo": 0.7, "Alto": 0.3}})
    ```
    *Nota: `balance_target` es un atajo para `custom_distributions={"col": "balanced"}`. Para desbalanceos extremos, los m√©todos de Deep Learning como `method="ctgan"` suelen ofrecer mayor estabilidad que los m√©todos basados en √°rboles.*
---
---

### `ddpm` - Synthcity TabDDPM (Difusi√≥n Tabular Avanzada)

**Tipo:** Deep Learning (Modelo de Difusi√≥n)
**Mejor para:** S√≠ntesis tabular de alta calidad, entornos de producci√≥n, grandes datasets
**Requisitos:** `synthcity` (incluido en instalaci√≥n base de deep learning)

**Type:** Deep Learning (Diffusion Model)  
**Best For:** High-quality tabular synthesis, production environments, large datasets  
**Requirements:** `synthcity` (included in base installation)

#### Descripci√≥n

TabDDPM (Tabular Denoising Diffusion Probabilistic Model) es la implementaci√≥n avanzada de modelos de difusi√≥n para datos tabulares de Synthcity. Ofrece m√∫ltiples arquitecturas, schedulers avanzados y calidad superior comparada con el m√©todo `diffusion` personalizado.

#### Cu√°ndo usarlo

‚úÖ **Usa `ddpm` cuando:**
- Necesitas **calidad m√°xima** en datos sint√©ticos
- Trabajas con **grandes datasets** (>100k filas)
- En **entornos de producci√≥n** que requieren c√≥digo robusto y mantenido
- Necesitas **arquitecturas avanzadas** (ResNet, TabNet)
- Quieres **cosine scheduling** para una mejor difusi√≥n
- Tienes **tiempo para entrenamientos largos** (1000 √©pocas por defecto)

‚ùå **No uses `ddpm` cuando:**
- Necesitas **prototipado r√°pido** (usa `diffusion` en su lugar)
- Trabajas con **datasets muy peque√±os** (<1k filas)
- Tienes **recursos computacionales limitados**
- Necesitas **modificaciones personalizadas** al algoritmo

#### Parameters

```python
synth = gen.generate(
    data,
    method='ddpm',
    n_samples=1000,
    
    # Training parameters
    n_iter=1000,                    # Training epochs (default: 1000)
    lr=0.002,                       # Learning rate (default: 0.002)
    batch_size=1024,                # Batch size (default: 1024)
    
    # Diffusion parameters
    num_timesteps=1000,             # Diffusion timesteps (default: 1000)
    scheduler='cosine',             # 'cosine' or 'linear' (default: 'cosine')
    gaussian_loss_type='mse',       # 'mse' or 'kl' (default: 'mse')
    
    # Model architecture
    model_type='mlp',               # 'mlp', 'resnet', or 'tabnet' (default: 'mlp')
    model_params={                  # Architecture-specific parameters
        'n_layers_hidden': 3,
        'n_units_hidden': 256,
        'dropout': 0.0
    },
    
    # Task type
    is_classification=False,        # True for classification tasks
)
```

#### Parameter Details

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `n_iter` | int | 1000 | Number of training epochs |
| `lr` | float | 0.002 | Learning rate for optimizer |
| `batch_size` | int | 1024 | Training batch size |
| `num_timesteps` | int | 1000 | Number of diffusion timesteps |
| `scheduler` | str | `'cosine'` | Beta scheduler: `'cosine'` (recommended) or `'linear'` |
| `gaussian_loss_type` | str | `'mse'` | Loss function: `'mse'` or `'kl'` |
| `model_type` | str | `'mlp'` | Architecture: `'mlp'`, `'resnet'`, or `'tabnet'` |
| `model_params` | dict | See above | Architecture-specific parameters |
| `is_classification` | bool | False | Set to True for classification tasks |

#### Model Types

**MLP (Multi-Layer Perceptron)**
- Best for: General tabular data
- Speed: Fast
- Parameters: `n_layers_hidden`, `n_units_hidden`, `dropout`

**ResNet (Residual Network)**
- Best for: Complex feature relationships
- Speed: Medium
- Parameters: `n_layers_hidden`, `n_units_hidden`, `dropout`

**TabNet**
- Best for: Tabular data with feature importance
- Speed: Slower
- Parameters: Specific to TabNet architecture

#### Comparison: `diffusion` vs `ddpm`

| Aspect | `diffusion` (custom) | `ddpm` (Synthcity) |
|--------|---------------------|-------------------|
| **Speed** | ‚ö° Fast (100 epochs) | üê¢ Slower (1000 epochs) |
| **Quality** | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê‚≠ê Excellent |
| **Architectures** | MLP only | MLP/ResNet/TabNet |
| **Scheduler** | Linear | Cosine/Linear |
| **Batch Size** | 64 | 1024 |
| **Use Case** | Quick prototyping | Production quality |
| **Customization** | Easy to modify | Black box |
| **Maintenance** | Your responsibility | Synthcity team |

#### Usage Examples

**Basic Usage:**
```python
from calm_data_generator import RealGenerator
import pandas as pd

gen = RealGenerator()
synth = gen.generate(
    data,
    method='ddpm',
    n_samples=1000,
    n_iter=500  # Reduce for faster training
)
```

**Classification Task:**
```python
synth = gen.generate(
    data,
    method='ddpm',
    n_samples=1000,
    is_classification=True,
    target_col='label'
)
```

**Advanced Architecture:**
```python
synth = gen.generate(
    data,
    method='ddpm',
    n_samples=1000,
    model_type='resnet',
    model_params={
        'n_layers_hidden': 5,
        'n_units_hidden': 512,
        'dropout': 0.1
    },
    scheduler='cosine',
    n_iter=2000
)
```

---

### `timegan` - TimeGAN (Time Series GAN)

**Tipo:** Deep Learning (GAN para Series Temporales)
**Mejor para:** Patrones temporales complejos, series temporales multi-entidad
**Requisitos:** `synthcity` (incluido en instalaci√≥n base)

#### Descripci√≥n

TimeGAN (Time-series Generative Adversarial Network) est√° dise√±ado espec√≠ficamente para datos secuenciales/temporales. Aprende tanto la din√°mica temporal como la distribuci√≥n de caracter√≠sticas, haci√©ndolo ideal para series temporales con patrones complejos.

#### Cu√°ndo usarlo

‚úÖ **Usa `timegan` cuando:**
- Tienes **datos de series temporales** con dependencias temporales
- Trabajas con **secuencias multi-entidad** (ej. m√∫ltiples usuarios/sensores)
- Necesitas preservar **din√°micas temporales**
- Tienes **patrones temporales complejos** para aprender
- Necesitas s√≠ntesis de series temporales de **alta calidad**

‚ùå **No uses `timegan` cuando:**
- Tienes **datos tabulares simples** (usa `ctgan` o `ddpm` en su lugar)
- Trabajas con **secuencias muy cortas** (<10 pasos de tiempo)
- Necesitas **generaci√≥n r√°pida** (usa `timevae` en su lugar)
- Tienes **recursos computacionales limitados**

#### Requisitos de Datos

TimeGAN espera datos en un formato temporal espec√≠fico:
- **Orden temporal**: Los datos deben estar ordenados por tiempo
- **Agrupaci√≥n por entidad**: Si es multi-entidad, agrupa por ID de entidad
- **Pasos consistentes**: Preferible intervalos de tiempo regulares

#### Parameters

```python
synth = gen.generate(
    data,
    method='timegan',
    n_samples=100,  # N√∫mero de secuencias a generar
    
    # Par√°metros de entrenamiento
    n_iter=1000,                    # √âpocas de entrenamiento (defecto: 1000)
    n_units_hidden=100,             # Unidades ocultas en RNN (defecto: 100)
    batch_size=128,                 # Tama√±o de batch (defecto: 128)
    lr=0.001,                       # Tasa de aprendizaje (defecto: 0.001)
)
```

#### Parameter Details

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `n_iter` | int | 1000 | Number of training epochs |
| `n_units_hidden` | int | 100 | Number of hidden units in RNN layers |
| `batch_size` | int | 128 | Training batch size |
| `lr` | float | 0.001 | Learning rate for optimizer |

#### Usage Examples

**Basic Time Series:**
```python
from calm_data_generator import RealGenerator
import pandas as pd

# Data must have temporal structure
# Example: sensor readings over time
gen = RealGenerator()
synth = gen.generate(
    time_series_data,
    method='timegan',
    n_samples=100,  # Generate 100 sequences
    n_iter=1000,
    n_units_hidden=100
)
```

**Multi-Entity Time Series:**
```python
# Data with multiple entities (e.g., users, sensors)
# Ensure data is sorted by entity_id and timestamp
synth = gen.generate(
    multi_entity_data,
    method='timegan',
    n_samples=50,  # Generate 50 entity sequences
    n_iter=2000,
    n_units_hidden=150,
    batch_size=64
)
```

---

### `timevae` - TimeVAE (Time Series VAE)

**Type:** Deep Learning (VAE for Time Series)  
**Best For:** Regular time series, faster training than TimeGAN  
**Requirements:** `synthcity` (included in base installation)

#### Description

TimeVAE is a variational autoencoder designed for temporal data. It's generally faster than TimeGAN and works well for regular time series with consistent patterns.

#### When to Use

‚úÖ **Use `timevae` when:**
- You have **regular time series** data
- You need **faster training** than TimeGAN
- Working with **consistent temporal patterns**
- You want **good quality** with **less computation**
- You have **moderate-length sequences**

‚ùå **No uses `timevae` when:**
- You have **highly irregular** time series
- You need **maximum quality** (use `timegan` instead)
- Working with **very complex** temporal dynamics
- You have **simple tabular data** (use `ctgan` or `ddpm`)

#### Data Requirements

Similar to TimeGAN:
- **Temporal ordering**: Data sorted by time
- **Regular intervals**: Works best with consistent timesteps
- **Entity grouping**: If multi-entity, group by entity ID

#### Parameters

```python
synth = gen.generate(
    data,
    method='timevae',
    n_samples=100,  # Number of sequences to generate
    
    # Training parameters
    n_iter=1000,                    # Training epochs (default: 1000)
    decoder_n_layers_hidden=2,      # Decoder layers (default: 2)
    decoder_n_units_hidden=100,     # Decoder units (default: 100)
    batch_size=128,                 # Batch size (default: 128)
    lr=0.001,                       # Learning rate (default: 0.001)
)
```

#### Parameter Details

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `n_iter` | int | 1000 | Number of training epochs |
| `decoder_n_layers_hidden` | int | 2 | Number of hidden layers in decoder |
| `decoder_n_units_hidden` | int | 100 | Number of hidden units in decoder |
| `batch_size` | int | 128 | Training batch size |
| `lr` | float | 0.001 | Learning rate for optimizer |

---

## Guardado y Carga de Modelos

`RealGenerator` permite guardar modelos generadores entrenados y cargarlos posteriormente para inferencia sin re-entrenar. Esto es √∫til para pipelines de producci√≥n donde el entrenamiento es costoso.

### Guardar un Modelo

Despu√©s de generar datos (lo cual entrena el modelo subyacente), puedes guardar el generador:

```python
# 1. Entrenar y Generar
gen.generate(data, n_samples=1000, method="ctgan", batch_size=500)

# 2. Guardar el generador entrenado
gen.save("models/mi_modelo_ctgan.pkl")
```
> **Nota:** El archivo guardado es un archivo zip que contiene la configuraci√≥n del `RealGenerator` y el modelo subyacente (ej. estado del plugin de Synthcity).

### Cargar un Modelo

Puedes cargar un modelo guardado usando el m√©todo de clase `load()`. Una vez cargado, puedes generar m√°s muestras sin proporcionar los datos de entrenamiento originales.

```python
from calm_data_generator.generators.tabular import RealGenerator

# 1. Cargar el generador
loaded_gen = RealGenerator.load("models/mi_modelo_ctgan.pkl")

# 2. Generar nuevas muestras (¬°No se necesita argumento 'data'!)
new_samples = loaded_gen.generate(n_samples=500)
```

> **Advertencia:** Al generar desde un modelo cargado, **no debes** pasar `data` a `generate()`, pero **debes** pasar `n_samples`.

---

## Mejores Pr√°cticas

6. **Desbalance severo:** Usa `smote` o `adasyn` con `target_col`.

#### Comparison: `timegan` vs `timevae`

| Aspect | `timegan` | `timevae` |
|--------|-----------|-----------|
| **Speed** | üê¢ Slower | ‚ö° Faster |
| **Quality** | ‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê Good |
| **Complexity** | Handles complex patterns | Best for regular patterns |
| **Training Time** | Longer | Shorter |
| **Use Case** | Complex temporal dynamics | Regular time series |

#### Usage Examples

**Basic Time Series:**
```python
from calm_data_generator import RealGenerator
import pandas as pd

gen = RealGenerator()
synth = gen.generate(
    time_series_data,
    method='timevae',
    n_samples=100,
    n_iter=500,  # Faster than TimeGAN
    decoder_n_units_hidden=100
)
```

**Faster Training:**
```python
# Reduce parameters for quick prototyping
synth = gen.generate(
    time_series_data,
    method='timevae',
    n_samples=50,
    n_iter=300,
    decoder_n_layers_hidden=1,
    decoder_n_units_hidden=50,
    batch_size=64
)
```

---

## Method Selection Guide

### For Tabular Data

| Scenario | Recommended Method | Alternative |
|----------|-------------------|-------------|
| **Quick prototyping** | `diffusion` | `cart`, `rf` |
| **Production quality** | `ddpm` | `ctgan` |
| **Large datasets (>100k)** | `ddpm`, `lgbm` | `ctgan` |
| **Small datasets (<1k)** | `cart`, `rf` | `diffusion` |
| **Class imbalance** | `smote`, `adasyn` | `ctgan` |
| **Preserve correlations** | `ctgan`, `ddpm` | `copula` |
| **Fast generation** | `cart`, `diffusion` | `rf` |
| **Maximum quality** | `ddpm` (ResNet) | `ctgan` |

### For Time Series Data

| Scenario | Recommended Method | Alternative |
|----------|-------------------|-------------|
| **Complex temporal patterns** | `timegan` | - |
| **Regular time series** | `timevae` | `timegan` |
| **Fast training** | `timevae` | - |
| **Multi-entity sequences** | `timegan` | `timevae` |
| **Maximum quality** | `timegan` | `timevae` |

### For Special Cases

| Data Type | Recommended Method |
|-----------|-------------------|
| **Single-cell RNA-seq** | `scvi` |
| **Clinical/Medical** | Use `ClinicalDataGenerator` |
| **Streaming data** | Use `StreamGenerator` |
| **Block/Batch data** | Use `RealBlockGenerator` |
